# ðŸ“Š NOLA God Level Coder - Analytics para Restaurantes

Esta Ã© a minha soluÃ§Ã£o para o desafio [NOLA God Level Coder](https://github.com/lucasvieira94/nola-god-level). O objetivo Ã© uma plataforma de analytics customizÃ¡vel para que donos de restaurantes, possam explorar seus dados operacionais de forma simples, flexÃ­vel e rÃ¡pida.

**Autora:** Fernanda Rcoha da Silva
**Prazo de Entrega:** 03/11/2025

---

## ðŸš€ DemonstraÃ§Ã£o (Deploy)

[!! SE VOCÃŠ FEZ O DEPLOY NO STREAMLIT CLOUD, INSIRA O LINK AQUI. SENÃƒO, APAGUE ESTA SEÃ‡ÃƒO E FOQUE NAS INSTRUÃ‡Ã•ES DO DOCKER ABAIXO !!]

---

## ðŸ›ï¸ A DecisÃ£o Arquitetural: Por que ETL + Parquet?

O ponto central da minha arquitetura foi uma decisÃ£o consciente para resolver o principal desafio tÃ©cnico: **Performance**.

### O Problema

O requisito de avaliaÃ§Ã£o era claro: "Queries otimizadas (menos de 1 segundo para 500k registros)". O schema de dados fornecido, apesar de realista, Ã© transacional (OLTP), exigindo mÃºltiplos e complexos `JOINs` para responder perguntas simples (ex: `sales` -> `product_sales` -> `products` -> `categories` -> `stores` -> `channels`).

Uma abordagem ingÃªnua, conectando o dashboard diretamente ao PostgreSQL e executando esses `JOINs` a cada clique de filtro, falharia miseravelmente no requisito de < 1s.

### A SoluÃ§Ã£o (Arquitetura OLAP)

Para garantir uma experiÃªncia de usuÃ¡rio "fluida" e performance instantÃ¢nea, optei por uma arquitetura analÃ­tica (OLAP) desacoplada em duas etapas:

1.  **ETL (Extract, Transform, Load):** Um script Python (`etl.py`) Ã© executado uma vez. Ele se conecta ao PostgreSQL, executa a query complexa com todos os `JOINs` *uma Ãºnica vez*, e transforma os dados em uma tabela "achatada" (denormalizada).
2.  **Data Mart (Parquet):** Este script salva o resultado em um arquivo `dados_analiticos.parquet`. O formato Parquet Ã© colunar, otimizado para compressÃ£o e leitura analÃ­tica de alta velocidade.
3.  **Dashboard (Streamlit):** O aplicativo `app.py` (o dashboard) **nunca toca no banco de dados**. Ele lÃª *apenas* o arquivo Parquet na memÃ³ria (usando `@st.cache_data`).

**Resultado:** A filtragem Ã© feita em *milissegundos* pelo Pandas, pois os dados jÃ¡ estÃ£o na memÃ³ria, prÃ©-processados. Isso nÃ£o sÃ³ atende, mas supera o requisito de performance.

---

## âœ¨ Funcionalidades Implementadas

O dashboard foi projetado para resolver as "Dores Atuais" do cliente:

* **Painel de KPIs DinÃ¢micos:** Cards no topo da pÃ¡gina mostram Faturamento Total, NÂº de Pedidos, Ticket MÃ©dio e Tempo MÃ©dio de Entrega, todos reagindo aos filtros em tempo real.
* **GrÃ¡fico de Performance por Hora:** Um grÃ¡fico de linha interativo que permite Ã  Maria visualizar os picos de venda ao longo do dia (ex: almoÃ§o vs. jantar).
* **Insights AutomÃ¡ticos (IA Baseada em Regras):** Um botÃ£o "Gerar Insights" que analisa os dados filtrados e aponta:
    * **Dia de Pico (Black Friday):** Detecta anomalias de faturamento (como o "Pico de 3x" injetado nos dados).
    * **HorÃ¡rio de Pico:** Informa qual a hora mais lucrativa.
    * **Canal Mais Usado:** Mostra qual canal (iFood, Rappi, etc.) teve mais pedidos.
* **Construtor de AnÃ¡lise (Pivot Table):** O coraÃ§Ã£o do dashboard. Permite que o usuÃ¡rio cruze qualquer MÃ©trica (ex: "Valor Total") com qualquer DimensÃ£o (ex: "Produto" por "Canal"), criando relatÃ³rios flexÃ­veis.
* **Filtros Globais:** Filtros na barra lateral por Data, Loja e Canal.
* **ExportaÃ§Ã£o para CSV:** Qualquer anÃ¡lise da tabela dinÃ¢mica pode ser exportada com um clique, atendendo ao critÃ©rio de "Exportar relatÃ³rio".
* **UI Customizada:** O dashboard usa um tema customizado (`.streamlit/config.toml`) para uma aparÃªncia profissional.

---

## ðŸ› ï¸ Stack TecnolÃ³gica

* **Infraestrutura:** Docker, Docker Compose
* **Banco de Dados:** PostgreSQL (para geraÃ§Ã£o de dados)
* **ETL (Backend):** Python, Pandas, SQLAlchemy (para conectar ao PG), PyArrow (para salvar Parquet)
* **Dashboard (Frontend):** Streamlit, Plotly Express (para grÃ¡ficos interativos), Pillow (para imagens)

---

## ðŸƒ Como Rodar (Entrega Docker)

Este projeto estÃ¡ 100% "dockerizado" para garantir que ele funcione perfeitamente, como solicitado no `FAQ.md` ("garanta que `docker compose up` funciona perfeitamente").

**PrÃ©-requisitos:**
* Docker Desktop (Instalado e em execuÃ§Ã£o)

### InstruÃ§Ãµes

1.  Clone este repositÃ³rio:
    ```bash
    git clone [!! INSIRA O LINK DO SEU REPOSITÃ“RIO GIT AQUI !!]
    ```

2.  Entre na pasta do projeto:
    ```bash
    cd nola-god-level
    ```

3.  Execute o Docker Compose para construir e iniciar todos os serviÃ§os (Banco, ETL e App):
    ```bash
    docker compose up --build
    ```

4.  **Aguarde!** O primeiro `up` irÃ¡:
    * Construir a imagem do `postgres` e iniciÃ¡-lo.
    * Construir a imagem do `app` (instalando o Streamlit, Pandas, etc.).
    * Assim que o banco estiver pronto, o container `app` irÃ¡ rodar o `etl.py`. (Isso pode levar de 1 a 3 minutos, vocÃª verÃ¡ o log "Iniciando script de ETL..." no seu terminal).
    * Assim que o ETL terminar, o servidor Streamlit iniciarÃ¡.

5.  Acesse o dashboard no seu navegador:
    **[http://localhost:8501](http://localhost:8501)**
